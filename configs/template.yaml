# General training parameters
experiment_name: simpleCLIPTrain
seed: 42
device: cuda  # or cpu
checkpoint_path: # Path to the checkpoint file, if start from an already trained model with this framework


# Data parameters
dataset:
  name: DSEC_Night
  data_dir: ./data
  batch_size: 8
  num_workers: 2
  train_type: "supervised" # can be ssl, supervised
  train_split: train
  val_split: val
  test_split: test

# Model parameters
model:
  name: 'model_name'
  head: 
    name: 'head_name' # redoundant here, but useful for clarity
    num_classes: 8
  backbone:
    name: '' # if name is empty -> stack of the two backbone will be used
    rgb_backbone: backbone_name # from timm
    pretrained: True # if not specified, it will be set to True
    pretrained_weights: #'detr_resnet50_weights.pth' # path to pretrained weights if needed
    embed_dim: 128
    input_size: 512
    output_indices: [1, 2, 3, 4] # indices of the output layers to be used
    #dropout: 0.25

# Optimizer parameters
optimizer:
  name: Adam
  lr: 0.001
  wd: 0.0005

# Loss function parameters
loss:
  name: CLIP

# Training loop parameters
trainer:
  epochs: 10
  log_interval: 100 # steps
  val_interval: 500 # steps
  checkpoint_interval: 1 # steps
  checkpoint_interval_epochs: 5 # save checkpoint every 5 epochs
  save_folder: ""

# Scheduler parameters (optional)
scheduler:
  name: ReduceLROnPlateau
  factor: 0.1
  patience: 3
  monitor: val_loss
  mode: min

# Logging parameters
logger:
  name: wandb
  project: Cross_Modality_Framework  # Replace with your wandb project name
  entity: TwoGuysOneCode
