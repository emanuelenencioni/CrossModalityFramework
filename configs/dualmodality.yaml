# General training parameters
experiment_name: simpleCLIPTrain
seed: 42
device: cuda  # or cpu
checkpoint_path: "" # path to a checkpoint to resume training from, if null training starts from scratch

# Data parameters
dataset:
  name: DSEC_Night
  data_dir: data
  batch_size: 4
  num_workers: 4
  outputs: ["events", "images", "BB", "img_metas", "labels"] # these mandatory for unimodal training
  custom_classes: True # if True, the model will use custom classes defined in the dataset
  bb_num_classes: 8 # according to DSEC
  train_split: "night_dataset.txt"
  val_split: "night_test_dataset.txt"
  use_augmentations: True
  augmentations:
    resize: [512, 1024] # height, width
    hflip_prob: 0.5
    scale: [0.8, 1.2]
    ratio: [0.9, 1.1]

#rgb
model1:
  name: 'resnet50_yolox'
  # when using this, the successive parameters will be ignored
  pretrained_weights: resnet50_uni_rgb_Adam_multistep_lr_noaug_20251016_222446_checkpoint_epoch_99_202510171030.pth #'../resnet50_backbone_from_detr.pth' # path to pretrained weights if needed
  head: 
    name: 'yolox_head' # redundant here, but useful for clarity
    num_classes: 8
    losses_weights: [5.0, 1.0, 1.0, 1.0]  # [iou, obj, cls, l1]
  backbone:
    name: 'resnet50' # if name is empty -> stack of the two backbone will be used
    pretrained: True # if not specified, it will be set to True
    pretrained_weights: #'../resnet50_backbone_from_detr.pth' # path to pretrained weights if needed
    embed_dim: 256
    input_size: 512
    output_indices: [3, 4] # indices of the output layers to be used
    #dropout: 0.25

#event
model2:
  freeze: True # if True, the model2 weights will not be updated during training
  name: 'resnet50_yolox'
  # when using this, the successive parameters will be ignored
  pretrained_weights: unimodal_events_saves_251016/resnet50_uni_event_Adam_ReduceLROnPlateau_noaug_20251018_170457_checkpoint_epoch_99_202510182304.pth #'../resnet50_backbone_from_detr.pth' # path to pretrained weights if needed
  head: 
    name: 'yolox_head' # redundant here, but useful for clarity
    num_classes: 8
    losses_weights: [0.0, 0.0, 0.0, 0.0]  # [iou, obj, cls, l1] # set to 0.0 to avoid computing the loss for model2
  backbone:
    name: 'resnet50' # if name is empty -> stack of the two backbone will be used
    pretrained: True # if not specified, it will be set to True
    pretrained_weights: #'../resnet50_backbone_from_detr.pth' # path to pretrained weights if needed
    embed_dim: 256
    input_size: 512
    output_indices: [3, 4]  # indices of the output layers to be used
    #dropout: 0.25

multi_modality_loss:
  name: CLIP
  temperature: 0.5
  features: flatten_feat # name of the feature to be used from the model output, select between 'preflatten_feat', 'flatten_feat', 'projected_feat'

# Optimizer parameters
optimizer:
  name: Adam
  lr: 0.005
  #momentum: 0.9
  wd: 0.0005

evaluator:
  conf_threshold: 0.3
  nms_threshold: 0.45

# Training loop parameters
trainer:
  epochs: 100
  log_interval: 500 # steps
  checkpoint_interval_epochs: 5 # save checkpoint every 5 epochs
  save_folder: dualModalty__chckpoints

# Scheduler parameters (optional)
scheduler:
  name: multistep_lr
  milestones: [10, 30, 50, 60] # epochs
  gamma: 0.4

# Logging parameters
logger:
  name: wandb
  project: Cross_Modality_Framework  # Replace with your wandb project name
  entity: TwoGuysOneCode
