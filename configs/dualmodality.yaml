# General training parameters
experiment_name: simpleCLIPTrain
seed: 42
device: cuda  # or cpu
checkpoint_path: "" # path to a checkpoint to resume training from, if null training starts from scratch

# Data parameters
dataset:
  name: DSEC_Night
  data_dir: data
  batch_size: 20
  num_workers: 10
  outputs: ["events", "images", "BB", "img_metas", "labels"] # these mandatory for unimodal training
  custom_classes: True # if True, the model will use custom classes defined in the dataset
  bb_num_classes: 8 # according to DSEC
  train_split: "night_dataset.txt"
  val_split: "night_test_dataset.txt"
  use_augmentations: True
  augmentations:
    resize: [512, 1024] # height, width
    hflip_prob: 0.5
    scale: [0.8, 1.2]
    ratio: [0.9, 1.1]

#rgb
model1:
  name: 'resnet50_yolox'
  head: 
    name: 'yolox_head' # redundant here, but useful for clarity
    num_classes: 8
    losses_weights: [5.0, 1.0, 1.0, 1.0]  # [iou, obj, cls, l1]
  backbone:
    name: 'rgb' # if name is empty -> stack of the two backbone will be used
    pretrained: True # if not specified, it will be set to True
    pretrained_weights: #'../resnet50_backbone_from_detr.pth' # path to pretrained weights if needed
    embed_dim: 256
    input_size: 512
    output_indices: [3, 4] # indices of the output layers to be used
    #dropout: 0.25

#event
model2:
  freeze: True # if True, the model2 weights will not be updated during training
  name: 'resnet50_yolox'
  head: 
    name: 'yolox_head' # redundant here, but useful for clarity
    num_classes: 8
    losses_weights: [5.0, 1.0, 1.0, 1.0]  # [iou, obj, cls, l1]
  backbone:
    name: 'event' # if name is empty -> stack of the two backbone will be used
    pretrained: True # if not specified, it will be set to True
    pretrained_weights: #'../resnet50_backbone_from_detr.pth' # path to pretrained weights if needed
    embed_dim: 256
    input_size: 512
    output_indices: [3, 4] # indices of the output layers to be used
    #dropout: 0.25

criterion:
  name: NTXentLoss
  temperature: 0.5
  features: projected_feat # name of the feature to be used from the model output

# Optimizer parameters
optimizer:
  name: Adam
  lr: 0.005
  #momentum: 0.9
  wd: 0.0005

evaluator:
  conf_threshold: 0.3
  nms_threshold: 0.45

# Training loop parameters
trainer:
  epochs: 100
  log_interval: 500 # steps
  checkpoint_interval_epochs: 5 # save checkpoint every 5 epochs
  save_folder: unimodal_rgb_checkpoints

# Scheduler parameters (optional)
scheduler:
  name: multistep_lr
  milestones: [10, 30, 50, 60] # epochs
  gamma: 0.4

# Logging parameters
logger:
  name: wandbasd
  project: Cross_Modality_Framework  # Replace with your wandb project name
  entity: TwoGuysOneCode
